import sys
import os
from pathlib import Path
import pandas as pd
import json
from apify_client import ApifyClient

# ConfiguraciÃ³n de paths
project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(project_root))

# Importar configuraciÃ³n
from config import APIFY_API_KEY, DB_PATH
from src.utils.database import get_db_connection, insert_dataframe_to_table

# ConfiguraciÃ³n de Apify
client = ApifyClient(APIFY_API_KEY)

# URLs de bÃºsqueda (vamos con calma, solo 2 primero)
SEARCH_URLS = [
    "https://www.tripadvisor.es/Restaurants-g187499-oa120-Girona_Province_of_Girona_Catalonia.html",
    "https://www.tripadvisor.es/Restaurants-g187499-oa150-Girona_Province_of_Girona_Catalonia.html"
]

def run_apify_actor_slow():
    """Ejecuta el actor de Apify con configuraciÃ³n ultra-lenta para evitar bloqueos"""
    print("ğŸš€ Ejecutando actor de Apify (modo lento)...")
    print(f"ğŸ“‹ NÃºmero de URLs: {len(SEARCH_URLS)}")
    
    try:
        run = client.actor("maxcopell/tripadvisor").call(
            run_input={
                "startUrls": [{"url": url} for url in SEARCH_URLS],
                "maxItems": 20,  # Muy pocos para empezar
                "proxyConfiguration": {
                    "useApifyProxy": True,
                    "apifyProxyGroups": ["RESIDENTIAL"],
                    "apifyProxyCountry": "ES"
                },
                "maxConcurrency": 1,      # Solo 1 request a la vez
                "minTimeBetweenRequests": 10000,  # 10 SEGUNDOS entre requests
                "searchLanguage": "es",
                "reviews": False,         # Solo datos de restaurantes
            },
            wait_secs=600  # Esperar hasta 10 minutos
        )
        
        print("ğŸ“¦ Recopilando datos...")
        dataset = client.dataset(run["defaultDatasetId"]).list_items().items
        
        if not dataset:
            print("âŒ No se encontraron datos")
            return None
        
        print(f"âœ… Se obtuvieron {len(dataset)} restaurantes")
        return dataset
        
    except Exception as e:
        print(f"âŒ Error ejecutando el actor de Apify: {e}")
        return None

def explore_dataset(dataset):
    """Explora y muestra los datos obtenidos"""
    print("\n" + "="*60)
    print("ğŸ” EXPLORACIÃ“N DE DATOS OBTENIDOS")
    print("="*60)
    
    if not dataset:
        print("No hay datos para explorar")
        return
    
    # Guardar datos crudos para anÃ¡lisis
    with open('data/raw/datos_crudos.json', 'w', encoding='utf-8') as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)
    print("ğŸ’¾ Datos crudos guardados en: data/raw/datos_crudos.json")
    
    # Mostrar informaciÃ³n bÃ¡sica
    print(f"ğŸ“Š Total de items: {len(dataset)}")
    
    # Analizar el primer item para ver la estructura
    first_item = dataset[0]
    print(f"\nğŸ“‹ Estructura del primer item ({len(first_item)} campos):")
    for key, value in first_item.items():
        value_type = type(value).__name__
        value_preview = str(value)[:50] + "..." if len(str(value)) > 50 else str(value)
        print(f"  {key}: {value_type} = {value_preview}")
    
    return pd.DataFrame(dataset)

def process_for_database(df_raw):
    """Procesa los datos para insertar en la base de datos"""
    print("\n" + "="*60)
    print("ğŸ”„ PROCESAMIENTO PARA BASE DE DATOS")
    print("="*60)
    
    restaurantes_data = []
    
    for _, item in df_raw.iterrows():
        restaurante = {
            'nombre': item.get('name', ''),
            'location_id': item.get('id'),
            'url': extract_url_path(item.get('webUrl', '')),
            'direccion': item.get('address', ''),
            'latitud': item.get('latitude'),
            'longitud': item.get('longitude'),
            'telefono': item.get('phone', ''),
            'menu_url': item.get('menuWebUrl', ''),
            'tipo_cocina': extract_cuisines(item.get('cuisines', [])),
            'rango_precio': item.get('priceLevel', ''),
            'puntuacion': item.get('rating'),
            'numero_resenas': item.get('numberOfReviews', 0),
            'ranking': item.get('rankingPosition'),
            'web_url': item.get('webUrl', '')
        }
        restaurantes_data.append(restaurante)
    
    df_clean = pd.DataFrame(restaurantes_data)
    print(f"âœ… Datos procesados: {len(df_clean)} restaurantes")
    print(f"ğŸ“‹ Columnas finales: {list(df_clean.columns)}")
    
    return df_clean

def extract_url_path(full_url):
    """Extrae solo la parte del path de la URL"""
    if full_url and 'tripadvisor.com' in full_url:
        return full_url.split('tripadvisor.com')[-1]
    return full_url

def extract_cuisines(cuisines_data):
    """Convierte cocinas a string"""
    if not cuisines_data:
        return ''
    
    if isinstance(cuisines_data, list):
        if cuisines_data and isinstance(cuisines_data[0], dict):
            return ', '.join([c.get('name', '') for c in cuisines_data])
        return ', '.join(cuisines_data)
    return str(cuisines_data)

def save_to_database(df_clean):
    """Guarda los datos en la base de datos"""
    print("\n" + "="*60)
    print("ğŸ’¾ GUARDANDO EN BASE DE DATOS")
    print("="*60)
    
    try:
        conn = get_db_connection()
        insert_dataframe_to_table(df_clean, 'Restaurantes', conn)
        conn.commit()
        conn.close()
        
        print(f"âœ… {len(df_clean)} restaurantes guardados exitosamente!")
        print("\nğŸ“‹ Preview de los datos:")
        print(df_clean[['nombre', 'ranking', 'puntuacion', 'numero_resenas']].head())
        
    except Exception as e:
        print(f"âŒ Error guardando en BD: {e}")
        raise

def main():
    """FunciÃ³n principal"""
    print("=" * 60)
    print("ğŸ½ï¸  EXTRACCIÃ“N DE DATOS DE RESTAURANTES - MODO SEGURO")
    print("=" * 60)
    
    # Paso 1: Ejecutar actor lentamente
    dataset = run_apify_actor_slow()
    if not dataset:
        return
    
    # Paso 2: Explorar datos
    df_raw = explore_dataset(dataset)
    
    # Paso 3: Procesar para BD
    df_clean = process_for_database(df_raw)
    
    # Paso 4: Guardar en BD
    save_to_database(df_clean)
    
    print("\nğŸ‰ Â¡Proceso completado exitosamente!")

if __name__ == "__main__":
    main()